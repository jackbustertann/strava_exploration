{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda29883d8d1f6d40a8a22efcd61dfbad11",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from ETL_pipeline_functions import last_date, iso_8601_to_unix, strava_token_exchange, request_activities, request_weather, request_splits, request_zones, append_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETL_pipeline():\n",
    "    # storing access token\n",
    "    access_token = strava_token_exchange()['access_token']\n",
    "\n",
    "    # storing last activity date in unix format\n",
    "    start_date = iso_8601_to_unix(last_date())\n",
    "\n",
    "    # requesting activities from past week\n",
    "    activities = request_activities(start_date, access_token)\n",
    "\n",
    "    # checking for activities\n",
    "    n = 0\n",
    "    n += len(activities)\n",
    "\n",
    "    # error handling for weeks with no activities\n",
    "    if n == 0:\n",
    "        return print(\"no activities to append\")\n",
    "\n",
    "    else:\n",
    "        # appending activities to csv file\n",
    "        append_requests(activities, 'activities.csv')\n",
    "\n",
    "        # storing ids for activities\n",
    "        activity_ids = list(map(lambda activity: activity['activity_id'], activities))\n",
    "\n",
    "        # requesting weather info for activities and appending to csv file\n",
    "        weather_list = request_weather(activity_ids, access_token)\n",
    "        n += append_requests(weather_list, 'activity_weather.csv')\n",
    "\n",
    "        # requesting split metrics for activities and appending to csv file\n",
    "        activity_splits = request_splits(activity_ids, access_token)\n",
    "        n += append_requests(activity_splits, 'activity_splits.csv')\n",
    "\n",
    "        # requesting hr and pace zones for activities and appending to csv file\n",
    "        activity_zones = request_zones(activity_ids, access_token)\n",
    "        n += append_requests(activity_zones, 'activity_zones.csv')\n",
    "    \n",
    "    # logging requests\n",
    "    date = datetime.now().strftime('%d/%m/%Y')\n",
    "    with open('request_log.csv', 'w', newline = '') as log_file:\n",
    "        csv_writer = csv.writer(log_file)\n",
    "        csv_writer.writerow([date, n])\n",
    "    \n",
    "    return print(\"ETL pipeline complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "activities.csv appended\nactivity_weather.csv appended\nactivity_splits.csv appended\nactivity_zones.csv appended\nETL pipeline complete\n"
    }
   ],
   "source": [
    "ETL_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "no activities to append\n"
    }
   ],
   "source": [
    "ETL_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_csv('activities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_pattern_matcher(activity_name):\n",
    "    key_words = ['Intervals', 'Track', 'Yasso']\n",
    "    for key_word in key_words:\n",
    "        if key_word in activity_name:\n",
    "            return True\n",
    "        else:\n",
    "            continue\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities['run_type'] = ''\n",
    "for index, row in activities.iterrows():\n",
    "    if interval_pattern_matcher(row['activity_name']) == True:\n",
    "        activities.at[index, 'run_type'] = 'I'\n",
    "    else:\n",
    "        if row['distance'] < 8000:\n",
    "            activities.at[index, 'run_type'] = 'SR'\n",
    "        elif row['distance'] < 16000:\n",
    "            activities.at[index, 'run_type'] = 'MR'\n",
    "        else:\n",
    "            activities.at[index, 'run_type'] = 'LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(activity_name):\n",
    "    position_pattern = re.compile('.*\\s(\\d+)[a-z]{2}.*')\n",
    "    position_pattern_2 = re.compile('.*\\((\\d+)[a-z]{2}.*')\n",
    "    if len(re.findall(position_pattern, activity_name)) == 1:\n",
    "        return re.findall(position_pattern, activity_name)[0]\n",
    "    elif len(re.findall(position_pattern_2, activity_name)) == 1:\n",
    "        return re.findall(position_pattern_2, activity_name)[0]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities['position'] = activities['activity_name'].map(lambda x: int(get_position(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parkrun_pattern_matcher(activity_name):\n",
    "    if ('PR' in activity_name) & ('WU' not in activity_name):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities['event_type'] = ''\n",
    "for index, row in activities.iterrows():\n",
    "    if parkrun_pattern_matcher(row['activity_name']) == True:\n",
    "        activities.at[index, 'event_type'] = 'PR'\n",
    "    else:\n",
    "        if row['position'] > 0:\n",
    "            if 'XC' in row['activity_name']:\n",
    "                activities.at[index, 'event_type'] = 'XCR'\n",
    "            else:\n",
    "                activities.at[index, 'event_type'] = 'RR'\n",
    "        elif row['run_type'] == 'I':\n",
    "            activities.at[index, 'event_type'] = 'I'\n",
    "        else:\n",
    "            activities.at[index, 'event_type'] = 'W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>activity_name</th>\n      <th>activity_id</th>\n      <th>activity_type</th>\n      <th>distance</th>\n      <th>time</th>\n      <th>elevation_gain</th>\n      <th>kudos</th>\n      <th>start_date</th>\n      <th>average_speed</th>\n      <th>max_speed</th>\n      <th>average_cadence</th>\n      <th>average_hr</th>\n      <th>max_hr</th>\n      <th>suffer_score</th>\n      <th>run_type</th>\n      <th>event_type</th>\n      <th>position</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Panshanger PR (18:12 - 2nd)</td>\n      <td>1807281354</td>\n      <td>Run</td>\n      <td>5000.0</td>\n      <td>1092</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>2018-08-25T08:00:00Z</td>\n      <td>4.579</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SR</td>\n      <td>PR</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Evening Run - Panshanger</td>\n      <td>1817344422</td>\n      <td>Run</td>\n      <td>4903.3</td>\n      <td>1127</td>\n      <td>58.0</td>\n      <td>5</td>\n      <td>2018-09-03T19:14:06Z</td>\n      <td>4.339</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>169.9</td>\n      <td>178.0</td>\n      <td>55.0</td>\n      <td>SR</td>\n      <td>W</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hatfield 5k Series - race 1 (17:55 - 32nd)</td>\n      <td>1821995859</td>\n      <td>Run</td>\n      <td>5000.0</td>\n      <td>1075</td>\n      <td>0.0</td>\n      <td>10</td>\n      <td>2018-09-05T18:45:13Z</td>\n      <td>4.651</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SR</td>\n      <td>RR</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Panshanger PR (18:21 - 2nd)</td>\n      <td>1826965116</td>\n      <td>Run</td>\n      <td>5000.0</td>\n      <td>1101</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>2018-09-08T08:00:56Z</td>\n      <td>4.541</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SR</td>\n      <td>PR</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Evening Run - Welwyn</td>\n      <td>1830984968</td>\n      <td>Run</td>\n      <td>8093.0</td>\n      <td>1998</td>\n      <td>97.0</td>\n      <td>6</td>\n      <td>2018-09-09T18:49:18Z</td>\n      <td>4.038</td>\n      <td>6.1</td>\n      <td>NaN</td>\n      <td>167.9</td>\n      <td>190.0</td>\n      <td>85.0</td>\n      <td>MR</td>\n      <td>W</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                activity_name  activity_id activity_type  \\\n0                 Panshanger PR (18:12 - 2nd)   1807281354           Run   \n1                   Evening Run - Panshanger    1817344422           Run   \n2  Hatfield 5k Series - race 1 (17:55 - 32nd)   1821995859           Run   \n3                 Panshanger PR (18:21 - 2nd)   1826965116           Run   \n4                        Evening Run - Welwyn   1830984968           Run   \n\n   distance  time  elevation_gain  kudos            start_date  average_speed  \\\n0    5000.0  1092             0.0      1  2018-08-25T08:00:00Z          4.579   \n1    4903.3  1127            58.0      5  2018-09-03T19:14:06Z          4.339   \n2    5000.0  1075             0.0     10  2018-09-05T18:45:13Z          4.651   \n3    5000.0  1101             0.0      6  2018-09-08T08:00:56Z          4.541   \n4    8093.0  1998            97.0      6  2018-09-09T18:49:18Z          4.038   \n\n   max_speed  average_cadence  average_hr  max_hr  suffer_score run_type  \\\n0        0.0              NaN         NaN     NaN           NaN       SR   \n1        7.0              NaN       169.9   178.0          55.0       SR   \n2        0.0              NaN         NaN     NaN           NaN       SR   \n3        0.0              NaN         NaN     NaN           NaN       SR   \n4        6.1              NaN       167.9   190.0          85.0       MR   \n\n  event_type  position  \n0         PR         2  \n1          W         0  \n2         RR        32  \n3         PR         2  \n4          W         0  "
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}