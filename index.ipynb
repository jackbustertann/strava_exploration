{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda29883d8d1f6d40a8a22efcd61dfbad11",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from ETL_pipeline_functions import last_date, iso_8601_to_unix, strava_token_exchange, request_activities, request_weather, request_splits, request_zones, append_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETL_pipeline():\n",
    "    # storing access token\n",
    "    access_token = strava_token_exchange()['access_token']\n",
    "\n",
    "    # storing last activity date in unix format\n",
    "    start_date = iso_8601_to_unix(last_date())\n",
    "\n",
    "    # requesting activities from past week\n",
    "    activities = request_activities(start_date, access_token)\n",
    "\n",
    "    # checking for activities\n",
    "    n = 0\n",
    "    n += len(activities)\n",
    "\n",
    "    # error handling for weeks with no activities\n",
    "    if n == 0:\n",
    "        return print(\"no activities to append\")\n",
    "\n",
    "    else:\n",
    "        # appending activities to csv file\n",
    "        append_requests(activities, 'activities.csv')\n",
    "\n",
    "        # storing ids for activities\n",
    "        activity_ids = list(map(lambda activity: activity['activity_id'], activities))\n",
    "\n",
    "        # requesting weather info for activities and appending to csv file\n",
    "        weather_list = request_weather(activity_ids, access_token)\n",
    "        n += append_requests(weather_list, 'activity_weather.csv')\n",
    "\n",
    "        # requesting split metrics for activities and appending to csv file\n",
    "        activity_splits = request_splits(activity_ids, access_token)\n",
    "        n += append_requests(activity_splits, 'activity_splits.csv')\n",
    "\n",
    "        # requesting hr and pace zones for activities and appending to csv file\n",
    "        activity_zones = request_zones(activity_ids, access_token)\n",
    "        n += append_requests(activity_zones, 'activity_zones.csv')\n",
    "    \n",
    "    # logging requests\n",
    "    date = datetime.now().strftime('%d/%m/%Y')\n",
    "    with open('request_log.csv', 'a', newline = '') as log_file:\n",
    "        csv_writer = csv.writer(log_file)\n",
    "        csv_writer.writerow([date, n])\n",
    "    \n",
    "    return print(\"ETL pipeline complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "activities.csv appended\nactivity_weather.csv appended\nactivity_splits.csv appended\nactivity_zones.csv appended\nETL pipeline complete\n"
    }
   ],
   "source": [
    "ETL_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "no activities to append\n"
    }
   ],
   "source": [
    "ETL_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_csv('activities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_pattern_matcher(activity_name):\n",
    "    key_words = ['Intervals', 'Track', 'Yasso']\n",
    "    for key_word in key_words:\n",
    "        if key_word in activity_name:\n",
    "            return True\n",
    "        else:\n",
    "            continue\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities['run_type'] = ''\n",
    "for index, row in activities.iterrows():\n",
    "    if interval_pattern_matcher(row['activity_name']) == True:\n",
    "        activities.at[index, 'run_type'] = 'I'\n",
    "    else:\n",
    "        if row['distance'] < 8000:\n",
    "            activities.at[index, 'run_type'] = 'SR'\n",
    "        elif row['distance'] < 16000:\n",
    "            activities.at[index, 'run_type'] = 'MR'\n",
    "        else:\n",
    "            activities.at[index, 'run_type'] = 'LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(activity_name):\n",
    "    position_pattern = re.compile('.*\\s(\\d+)[a-z]{2}.*')\n",
    "    position_pattern_2 = re.compile('.*\\((\\d+)[a-z]{2}.*')\n",
    "    if len(re.findall(position_pattern, activity_name)) == 1:\n",
    "        return re.findall(position_pattern, activity_name)[0]\n",
    "    elif len(re.findall(position_pattern_2, activity_name)) == 1:\n",
    "        return re.findall(position_pattern_2, activity_name)[0]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities['position'] = activities['activity_name'].map(lambda x: int(get_position(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parkrun_pattern_matcher(activity_name):\n",
    "    if ('PR' in activity_name) & ('WU' not in activity_name):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities['event_type'] = ''\n",
    "for index, row in activities.iterrows():\n",
    "    if parkrun_pattern_matcher(row['activity_name']) == True:\n",
    "        activities.at[index, 'event_type'] = 'PR'\n",
    "    else:\n",
    "        if row['position'] > 0:\n",
    "            if 'XC' in row['activity_name']:\n",
    "                activities.at[index, 'event_type'] = 'XCR'\n",
    "            else:\n",
    "                activities.at[index, 'event_type'] = 'RR'\n",
    "        elif row['run_type'] == 'I':\n",
    "            activities.at[index, 'event_type'] = 'I'\n",
    "        else:\n",
    "            activities.at[index, 'event_type'] = 'W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities['location'] = ''\n",
    "for index, row in activities.iterrows():\n",
    "    if row['event_type'] == 'PR':\n",
    "        location_pattern = re.compile('(\\w+)\\s.*')\n",
    "        activities.at[index, 'location'] = re.findall(location_pattern, row['activity_name'])[0]\n",
    "    elif row['event_type'] == 'XCR':\n",
    "        activities.at[index, 'location'] = 'Other'\n",
    "    elif row['event_type'] == 'W':\n",
    "        location_pattern_1 = re.compile('.*\\s-\\s(\\w+)')\n",
    "        location_pattern_2 = re.compile('Treadmill.*')\n",
    "        if len(re.findall(location_pattern_1, row['activity_name'])) == 1:\n",
    "            activities.at[index, 'location'] = re.findall(location_pattern_1, row['activity_name'])[0]\n",
    "        elif len(re.findall(location_pattern_2, row['activity_name'])) == 1:\n",
    "            activities.at[index, 'location'] = 'Treadmill'\n",
    "        else:\n",
    "            activities.at[index, 'location'] = 'Other'    \n",
    "    elif row['event_type'] == 'I':\n",
    "        location_pattern = re.compile('Track.*')\n",
    "        if len(re.findall(location_pattern, row['activity_name'])) == 1:\n",
    "            activities.at[index, 'location'] = 'Track'\n",
    "        else:\n",
    "            activities.at[index, 'location'] = 'Welwyn'\n",
    "    else:\n",
    "        location_pattern_1 = re.compile('Hatfield\\s5.*')\n",
    "        if len(re.findall(location_pattern_1, row['activity_name'])) == 1:\n",
    "            activities.at[index, 'location'] = 'Hatfield'\n",
    "        else:\n",
    "            activities.at[index, 'location'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities['location'] = activities['location'].map(lambda x: 'Hatfield' if x == 'Ellenbrook' else x)\n",
    "activities['location'] = activities['location'].map(lambda x: 'Other' if x not in ['Welwyn', 'Panshanger', 'Hatfield', 'Treadmill', 'Track'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}